// Quick Ollama diagnostic script
const checkOllama = async () => {
  console.log('üîç Checking Ollama setup...\n');
  
  const baseURL = 'http://127.0.0.1:11434';
  const modelName = 'qwen2.5:1.5b';
  
  try {
    // Check if Ollama is running
    console.log('1. Checking if Ollama is running...');
    const healthResponse = await fetch(`${baseURL}/api/tags`, {
      signal: AbortSignal.timeout(5000)
    });
    
    if (!healthResponse.ok) {
      throw new Error(`Ollama not responding: ${healthResponse.status}`);
    }
    
    console.log('‚úÖ Ollama is running');
    
    // Check available models
    console.log('\n2. Checking available models...');
    const modelsData = await healthResponse.json();
    const models = modelsData.models || [];
    
    console.log('Available models:');
    models.forEach(model => {
      console.log(`  - ${model.name} (${(model.size / 1024 / 1024 / 1024).toFixed(1)}GB)`);
    });
    
    // Check if our model exists
    const hasModel = models.some(model => 
      model.name === modelName || model.name.startsWith(modelName.split(':')[0])
    );
    
    if (!hasModel) {
      console.log(`\n‚ùå Model ${modelName} not found!`);
      console.log(`\nüîß To fix this, run:`);
      console.log(`   ollama pull ${modelName}`);
      return;
    }
    
    console.log(`‚úÖ Model ${modelName} is available`);
    
    // Test a simple chat request
    console.log('\n3. Testing chat functionality...');
    const chatResponse = await fetch(`${baseURL}/api/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: modelName,
        messages: [{ role: 'user', content: 'Hello, respond with just "OK"' }],
        stream: false
      }),
      signal: AbortSignal.timeout(30000)
    });
    
    if (!chatResponse.ok) {
      throw new Error(`Chat test failed: ${chatResponse.status}`);
    }
    
    const chatData = await chatResponse.json();
    console.log('‚úÖ Chat test successful');
    console.log(`Response: ${chatData.message?.content || 'No content'}`);
    
    console.log('\nüéâ Ollama setup is working correctly!');
    
  } catch (error) {
    console.error('\n‚ùå Ollama check failed:', error.message);
    
    if (error.name === 'AbortError' || error.message.includes('timeout')) {
      console.log('\nüîß Timeout detected. Try these solutions:');
      console.log('1. Use a smaller model: ollama pull qwen2.5:0.5b');
      console.log('2. Increase system memory');
      console.log('3. Close other applications');
    } else if (error.message.includes('fetch')) {
      console.log('\nüîß Connection failed. Try these solutions:');
      console.log('1. Start Ollama: ollama serve');
      console.log('2. Check if port 11434 is available');
      console.log('3. Restart Ollama service');
    }
  }
};

// Run the check
checkOllama();